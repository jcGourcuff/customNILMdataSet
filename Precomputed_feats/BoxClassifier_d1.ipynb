{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BoxClassifier.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YslGTjk13_Su",
        "colab_type": "text"
      },
      "source": [
        "This notebook contains the computer vision task aimed to perform the computer vision task that goes within a NILM framework. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcSvSO3Q4XrR",
        "colab_type": "text"
      },
      "source": [
        "# Imports\n",
        "\n",
        "### Librairies\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOXkQx964Wwq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import torchvision\n",
        "from torchvision import models,transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "from skimage import io\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6oq8dT0H46JX",
        "colab_type": "text"
      },
      "source": [
        "### Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcBmydAW48YH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5334b55c-bc8f-4d19-911b-0f21ec53f7a7"
      },
      "source": [
        "!git clone https://github.com/jcGourcuff/customNILMdataSet.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'customNILMdataSet' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Xm9rHcR5Pjl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "666c2acb-e582-4860-a24d-38ccefd8f15d"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "customNILMdataSet  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbOrtpaO52CM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "root_dir = 'customNILMdataSet/'"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7EITaWY6EcB",
        "colab_type": "text"
      },
      "source": [
        "# Set up\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_fU6idECt0p",
        "colab_type": "text"
      },
      "source": [
        "### Class encoding\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hLBz_oQ6NZx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "34db15aa-de9c-470e-ebcd-d753e549b19e"
      },
      "source": [
        "classes = ['residuals', 'oven', 'refrigerator', 'dishwasher', 'kitchen_outlets', 'lighting', 'washer_dryer', 'microwave', 'bathroom_gfi']\n",
        "lab_encoder= OneHotEncoder(sparse = False)\n",
        "lab_encoder.fit([[name] for name in classes])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OneHotEncoder(categories='auto', drop=None, dtype=<class 'numpy.float64'>,\n",
              "              handle_unknown='error', sparse=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdMcXTC56pFK",
        "colab_type": "text"
      },
      "source": [
        "### Data set embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tz0RZ_D6uzm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BoxDataSet(Dataset):\n",
        "\n",
        "    def __init__(self, transform, encoder, batch_size, nb_app):\n",
        "        self.labels = pd.read_csv(root_dir + str(nb_app) + '_apps/labels.csv', compression = 'zip').set_index('id')\n",
        "        self.transform = transform\n",
        "        self.encoder = encoder\n",
        "        self.batch_size = batch_size\n",
        "        self.nb_app = nb_app\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.batch_size*(self.labels.shape[0]//self.batch_size)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "        id = self.labels.index[idx]\n",
        "        label = torch.FloatTensor(self.encoder.transform([[self.labels.loc[id,'label']]])[0])\n",
        "        img = self.extract_img(id)\n",
        "\n",
        "        sample = {'id':id,'image':img,'label':label}\n",
        "\n",
        "        return sample\n",
        "\n",
        "    def extract_img(self, img_id):\n",
        "        img_name = root_dir + str(self.nb_app) + '_apps/images/' + str(img_id) + '.png'\n",
        "        try:\n",
        "          img = Image.open(img_name) # open the image file\n",
        "          img.verify() # verify that it is, in fact an image\n",
        "          img.close()\n",
        "        except (IOError, SyntaxError) as e:\n",
        "          print('Bad file:', img_name)\n",
        "        img =  np.array(Image.open(img_name).convert(\"RGB\"))\n",
        "        img = torch.as_tensor(self.transform(img))[:,-4850:,:]\n",
        "        return img"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pcBPPGjA8NMC",
        "colab_type": "text"
      },
      "source": [
        "#### Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IcrFW_p8RI5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "transform_image = transforms.Compose([transforms.ToTensor(),normalize])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_mSE9hP7_Sy",
        "colab_type": "text"
      },
      "source": [
        "#### Vizualisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dyJQmIQX79sq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def imshow(inp, title=None):\n",
        "#   Imshow for Tensor.\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = np.clip(std * inp + mean, 0,1)\n",
        "    plt.figure(figsize = (40,8) )\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.pause(0.001)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlzIw6st7zS2",
        "colab_type": "text"
      },
      "source": [
        "#### Test data loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQI_h4wU7335",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        },
        "outputId": "87be5f5f-5434-4fa1-d456-1866a95fd9ec"
      },
      "source": [
        "test_set = BoxDataSet(transform=transform_image, encoder = lab_encoder, batch_size = 1, nb_app = 2)\n",
        "test_loader = DataLoader(test_set, batch_size = 1, shuffle=True, num_workers = 1)\n",
        "\n",
        "batch_test = next(iter(test_loader))\n",
        "out = torchvision.utils.make_grid(batch_test['image'])\n",
        "imshow(out, title=[lab_encoder.inverse_transform([batch_test['label'][x].numpy()])[0][0]for x in range(1)])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 2880x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQiKBjh09mZ_",
        "colab_type": "text"
      },
      "source": [
        "### Using GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_jeg_o882yG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bc6759e7-47ce-41c3-92eb-a5a7b5f07c48"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print('Using gpu: %s ' % torch.cuda.is_available())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using gpu: True \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rH--XRBjKG6F",
        "colab_type": "text"
      },
      "source": [
        "# Features precomputing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejMfdNE0LI3c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Model used for computing the features\n",
        "pretrained_model = models.resnet18(pretrained = True).to(device)\n",
        "pretrained_model_feats = nn.Sequential(*list(pretrained_model.children())[:-1])\n",
        "for param in pretrained_model_feats.parameters():\n",
        "    param.requires_grad = False"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhxPrcOOKL7C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preconvfeat(dataloader):\n",
        "    print(\"Precomputing features...\")\n",
        "    conv_features = []\n",
        "    labels_list = []\n",
        "    N = len(dataloader)\n",
        "    k=0\n",
        "    for data in dataloader:\n",
        "        print(\"\\r{}%\".format(np.round(100*k/N, decimals = 2)), end = '')\n",
        "        k+=1\n",
        "        inputs = data['image'].to(device)\n",
        "        labels = data['label'].to(device)\n",
        "        x = pretrained_model_feats(inputs)\n",
        "        conv_features.extend(x.data.cpu().numpy())\n",
        "        labels_list.extend(labels.data.cpu().numpy())\n",
        "\n",
        "        if k == 100 :\n",
        "          break\n",
        "\n",
        "    conv_features = np.concatenate([[feat] for feat in conv_features])\n",
        "    return (conv_features,labels_list)\n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHvoWBO6PsLz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "51880db6-8a7e-46bf-ac21-e8b65dea8ad5"
      },
      "source": [
        "conv_feats, conv_labels = preconvfeat(test_loader)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precomputing features...\n",
            "0.74%"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZQ419MTUEGP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datasetfeat = [[torch.from_numpy(f).type(torch.float),torch.tensor(l).type(torch.long)] for (f,l) in zip(conv_feats,conv_labels)]\n",
        "datasetfeat = [(inputs.reshape(-1), classes) for [inputs,classes] in datasetfeat]\n",
        "loaderfeat = DataLoader(datasetfeat, batch_size=33, shuffle=True)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4d5O-_4-ZxI",
        "colab_type": "text"
      },
      "source": [
        "# Model creation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ge3Z4qCe9wQO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BoxNet(nn.Module):\n",
        "    \"\"\"\n",
        "    Implements the NN that outputs the proba at time t that the corresponding app is on.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, output_size):\n",
        "        super(BoxNet, self).__init__()\n",
        "        self.output_size = output_size\n",
        "\n",
        "\n",
        "        #self.model = models.resnet18(pretrained = True)\n",
        "\n",
        "        #for param in self.model.parameters():\n",
        "        #    param.requires_grad = False\n",
        "\n",
        "        self.model = nn.Sequential(nn.Dropout(inplace=False),\n",
        "                                nn.Linear(512, 512),\n",
        "                                nn.ReLU(inplace=True),\n",
        "                                nn.BatchNorm1d(512),\n",
        "                                nn.Dropout(inplace = False),\n",
        "                                nn.Linear(512, 512),\n",
        "                                nn.ReLU(inplace=True),\n",
        "                                nn.BatchNorm1d(512),\n",
        "                                nn.Dropout(inplace = False),\n",
        "                                nn.Linear(512, self.output_size))\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.model(x)\n",
        "        return x"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9mbHIBhAD5s",
        "colab_type": "text"
      },
      "source": [
        "# Training and testing loops"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omQJF77bAH-r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(model,dataloader,size,epochs=1,optimizer=None):\n",
        "    model.train()\n",
        "    batch_count = 1\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        running_corrects = 0\n",
        "        for inputs, targets in dataloader:\n",
        "            print(\"\\rbatch {}\".format(batch_count), end = '')\n",
        "            batch_count+=1\n",
        "            inputs = inputs.to(device)\n",
        "            targets = targets.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = loss_fn(outputs,targets)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            _,preds = torch.max(F(outputs.data),1)\n",
        "            # statistics\n",
        "            running_loss += loss.data.item()\n",
        "            _,classs =  torch.max(targets,1)\n",
        "            running_corrects += torch.sum(preds == classs)\n",
        "        epoch_loss = running_loss / size\n",
        "        epoch_acc = running_corrects.data.item() / size\n",
        "        print('Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                     epoch_loss, epoch_acc))"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYBBPZkJATWQ",
        "colab_type": "text"
      },
      "source": [
        "# Instanciating and training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVvmTHMyAcdI",
        "colab_type": "text"
      },
      "source": [
        "### Training without selecting the images\n",
        "\n",
        "In this first part we will train the model on dignals composed of a pre-defined number of apps. There is no selction made on the images we pick. Thus there are high chances that the model overfits over-represented classes and that parasite samples come to blur the rules we are trying to infer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruGqi2LNCPAP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nb_outputs_ = 9"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TdyXP-9-kmp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BoxModel = BoxNet(nb_outputs_).to(device)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XARyYNjv-szv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "F = nn.Sigmoid().to(device)\n",
        "loss_fn = nn.BCEWithLogitsLoss().to(device)\n",
        "batch_size_ = 1\n",
        "lr_ = 0.001\n",
        "optimizer = torch.optim.Adam(BoxModel.parameters(), lr=lr_)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-x3wgCzBfMr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Set_2apps = BoxDataSet(transform=transform_image, encoder = lab_encoder, batch_size = batch_size_, nb_app = 2)\n",
        "Loader_2apps = DataLoader(Set_2apps, batch_size = batch_size_, shuffle=True, num_workers = 1)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "loAxoj50EJ0q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 695
        },
        "outputId": "cfb1756c-da81-446b-b487-776362db3ff5"
      },
      "source": [
        "train_model(BoxModel,dataloader = loaderfeat, size = len(loaderfeat),epochs=10,optimizer=optimizer)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rbatch 1"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-bb0db2876731>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBoxModel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloaderfeat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloaderfeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-26-e0f4ee6cf1d3>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, dataloader, size, epochs, optimizer)\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    615\u001b[0m                                                   \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m                                                   \u001b[0mpos_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 617\u001b[0;31m                                                   reduction=self.reduction)\n\u001b[0m\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy_with_logits\u001b[0;34m(input, target, weight, size_average, reduce, reduction, pos_weight)\u001b[0m\n\u001b[1;32m   2433\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Target size ({}) must be the same as input size ({})\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2435\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy_with_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction_enum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: result type Float can't be cast to the desired output type Long"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GWgMQBJEkfA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}